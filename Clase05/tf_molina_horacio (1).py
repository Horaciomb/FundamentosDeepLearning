# -*- coding: utf-8 -*-
"""tf_molina_horacio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/110JDrsDR52rt1Ar8-Qp0mYJ3QyqDTeOx

## **Instrucciones**
* Antes de iniciar debe hacer una copia del notebook (Archivo > Guardar una copia en Drive)
* Debe completar el codigo faltante donde se marca "# TU CODIGO AQUI". Al agregar el código borra "# TU CODIGO AQUI".
* Una vez finalizada la tarea debe descargar el notebook (Archivo > Descargar > Descargar .ipynb) y enviar el archivo con los nombres de los integrantes del equipo a fernandosilva.clases@gmail.com hasta máximo el lunes 29 de Abril a horas 23:59 hora Bolivia.
* El trabajo final puede ser realizado de manera individual o grupal (máximo 4 alummnos por grupo)
* En caso de realizar el trabajo de manera grupal, solo debe enviar la tarea un integrante del grupo.
* En caso de realizar el trabajo de manera grupal, no se considerará si hay mas de 3 alumnos en el grupo.
* El nombre del archivo final debe ser en el siguiente formato: "tf_perez_juan.ipynb" donde el nombre es Juan Perez.

### Nombres integrantes:
* Arrazola Juan Pablo
* Brito Paolo
* Gutierrez José
* Molina Horacio

---

# Trabajo Final

### Descripción del trabajo final

Este trabajo consiste en aplicar Redes Neuronales y modelos de Machine Learning supervisado para analizar y predecir el puntaje crediticio (credit score) de clientes utilizando un conjunto de datos realista. Se emplearán técnicas de preprocesamiento de datos, como la normalización y codificación de variables, y se evaluarán múltiples modelos vistos en clase, y Redes Neuronales, para identificar el modelo más adecuado para esta tarea. También se realizarán métricas de desempeño para comprender mejor el comportamiento de cada modelo.

### Objetivo

El objetivo es desarrollar, implementar y comparar modelos de Machine Learning Supervisado, así como Redes Neuronales, para predecir con precisión el puntaje crediticio de clientes. Además, se busca identificar los factores más relevantes en la predicción y proporcionar una base sólida para la toma de decisiones en el ámbito financiero.

---

## Parte A: Pre-procesamiento (10 puntos)
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt

"""### Cargamos el dataset

Estás trabajando en una empresa financiera global. A lo largo de los años, la empresa ha recopilado detalles básicos de cuentas bancarias y ha reunido mucha información relacionada con el crédito. La dirección quiere desarrollar un sistema inteligente para clasificar a las personas en rangos de puntuación crediticia, con el objetivo de reducir los esfuerzos manuales. El dataset que usarás es sobre clasificación de puntuación crediticia.
"""

data = pd.read_csv('https://raw.githubusercontent.com/delveeducation/datasets/refs/heads/main/credit_score.csv')

"""### Seleccionamos características relevantes y el target"""

relevant_features = ['age', 'annual_income', 'monthly_inhand_salary', 'total_emi_per_month',
                     'num_bank_accounts', 'num_credit_card', 'interest_rate', 'num_of_loan',
                     'num_of_delayed_payment', 'outstanding_debt', 'credit_utilization_ratio',
                     'amount_invested_monthly', 'monthly_balance']

target = 'credit_score'

"""### Filtramos columnas"""

data = data[relevant_features + [target]]

"""### Transformamos el target a valores numéricos"""

label_encoder = LabelEncoder()
data[target] = label_encoder.fit_transform(data[target])

"""### Lidiamos con valores faltantes

Utliza la media para rellenar los datos faltantes:
"""

data = data.fillna(data.mean())

"""### Separamos características y target"""

X = data[relevant_features]
y = data[target]

"""### Normalizamos las características"""

scaler = StandardScaler()
X = scaler.fit_transform(X)

"""### Dividimos en conjuntos de entrenamiento y prueba

[texto del enlace](https://)Utiliza el 20% para el test size y un random state de 42
"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""[texto del enlace](https://)## Parte B: Aplica Redes Neuronales (45 puntos)

### Importamos lo necesario
"""

from keras.models import Sequential
from keras.layers import Dense

"""### Creamos el modelo

En el siguiente codigo se proponen 4 capas (contando la de salida) puedes utilizar mas si consideras necesario.

* Pista 1: Tal como lo mencionamos en clase, utiliza el numero de nodos en base a potencias de 2, es decir 8, 16, 32,...
* Pista 2: Más capas no significa necesarimante mejor rendimiento.
* Pista 3: Si tienes overfitting, recuerda que puedes utilizar dropout-
* Pista 4: Revisa cuantas clases tienes en el target para definir el numero de nodos en la clase de salida, y en base a esto el tipo de función de activación que usarás.
"""

model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(#TU CODIGO AQUI, activation='#TU CODIGO AQUI'),
    Dense(#TU CODIGO AQUI, activation='#TU CODIGO AQUI'),
    Dense(#TU CODIGO AQUI, activation='#TU CODIGO AQUI')
])

"""### Compilamos el modelo

Recuerda que el loss function depende del tipo de función de activación que utilizarás en tu capa de salida de tu red neuronal.
"""

model.compile(optimizer=#TU CODIGO AQUI, loss=#TU CODIGO AQUI, metrics=['accuracy'])

"""### Entrenamos el modelo y guardamos el historial"""

history = model.fit(#TU CODIGO AQUI,
                    #TU CODIGO AQUI,
                    epochs=100,
                    batch_size=32,
                    validation_data=(#TU CODIGO AQUI, #TU CODIGO AQUI),
                    verbose=1)

"""### Graficamos las pérdidas de entrenamiento y validación"""

plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Train vs Validation Loss')
plt.legend()
plt.grid(True)
plt.show()

"""### Evaluamos el modelo

Debes obtener un accuracy mayor o igual a 0.68 y Perdida menor o igual a 0.68
"""

loss, accuracy = model.evaluate(#TU CODIGO AQUI, #TU CODIGO AQUI)
print(f"Red Neuronal - Pérdida: {loss}, Accuracy: {accuracy}")

"""## Parte C: Aplica dos modelos supervisados al mismo dataset (45 puntos)
* Aplica dos modelos a elección.
* Añade el accuracy de cada modelo.
"""

