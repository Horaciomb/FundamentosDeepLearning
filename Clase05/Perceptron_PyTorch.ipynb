{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5qKexDFpwkg"
      },
      "source": [
        "Importamos las librerias necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8WqofDpmpvRR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR-iKzElpzVU"
      },
      "source": [
        "Creamos nuestro toy dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3YSiAqMjpidS"
      },
      "outputs": [],
      "source": [
        "# X son las entradas, y son las etiquetas (0 o 1)\n",
        "X = torch.tensor([[1.0, 2.0], [2.0, 3.0],\n",
        "                  [3.0, 4.0], [4.0, 5.0]], requires_grad=True)\n",
        "y = torch.tensor([0.0, 0.0, 1.0, 1.0]).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bfE25VF2po5j"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PZoDbhYIprRz"
      },
      "outputs": [],
      "source": [
        "# Definimos la función de pérdida y el optimizador\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Tz2CMlpsxN",
        "outputId": "b0e4904d-5f83-4e32-f04e-fdb3c7cebd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 1 ---\n",
            "tensor([1., 2.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 1:\n",
            "  Antes del backward: Pesos [[ 0.26275092 -0.66824937]]\n",
            "  Gradientes calculadas: [[0.15201478 0.30402955]]\n",
            "  Después del step: Pesos actualizados [[ 0.24754944 -0.6986523 ]]\n",
            "tensor([2., 3.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 2:\n",
            "  Antes del backward: Pesos [[ 0.24754944 -0.6986523 ]]\n",
            "  Gradientes calculadas: [[0.18877599 0.28316396]]\n",
            "  Después del step: Pesos actualizados [[ 0.22867185 -0.7269687 ]]\n",
            "tensor([3., 4.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 3:\n",
            "  Antes del backward: Pesos [[ 0.22867185 -0.7269687 ]]\n",
            "  Gradientes calculadas: [[-2.8422942 -3.7897258]]\n",
            "  Después del step: Pesos actualizados [[ 0.5129013  -0.34799612]]\n",
            "tensor([4., 5.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 4:\n",
            "  Antes del backward: Pesos [[ 0.5129013  -0.34799612]]\n",
            "  Gradientes calculadas: [[-2.2618976 -2.827372 ]]\n",
            "  Después del step: Pesos actualizados [[ 0.73909104 -0.06525889]]\n",
            "\n",
            "--- Epoch 2 ---\n",
            "tensor([1., 2.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 1:\n",
            "  Antes del backward: Pesos [[ 0.73909104 -0.06525889]]\n",
            "  Gradientes calculadas: [[0.5225063 1.0450126]]\n",
            "  Después del step: Pesos actualizados [[ 0.6868404  -0.16976015]]\n",
            "tensor([2., 3.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 2:\n",
            "  Antes del backward: Pesos [[ 0.6868404  -0.16976015]]\n",
            "  Gradientes calculadas: [[1.1457851 1.7186776]]\n",
            "  Después del step: Pesos actualizados [[ 0.5722619  -0.34162793]]\n",
            "tensor([3., 4.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 3:\n",
            "  Antes del backward: Pesos [[ 0.5722619  -0.34162793]]\n",
            "  Gradientes calculadas: [[-1.7069857 -2.275981 ]]\n",
            "  Después del step: Pesos actualizados [[ 0.7429605  -0.11402982]]\n",
            "tensor([4., 5.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 4:\n",
            "  Antes del backward: Pesos [[ 0.7429605  -0.11402982]]\n",
            "  Gradientes calculadas: [[-0.5526838 -0.6908547]]\n",
            "  Después del step: Pesos actualizados [[ 0.79822886 -0.04494435]]\n",
            "\n",
            "--- Epoch 3 ---\n",
            "tensor([1., 2.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 1:\n",
            "  Antes del backward: Pesos [[ 0.79822886 -0.04494435]]\n",
            "  Gradientes calculadas: [[0.53768593 1.0753719 ]]\n",
            "  Después del step: Pesos actualizados [[ 0.7444603  -0.15248154]]\n",
            "tensor([2., 3.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 2:\n",
            "  Antes del backward: Pesos [[ 0.7444603  -0.15248154]]\n",
            "  Gradientes calculadas: [[1.2071565 1.8107347]]\n",
            "  Después del step: Pesos actualizados [[ 0.6237446 -0.333555 ]]\n",
            "tensor([3., 4.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 3:\n",
            "  Antes del backward: Pesos [[ 0.6237446 -0.333555 ]]\n",
            "  Gradientes calculadas: [[-1.6006658 -2.134221 ]]\n",
            "  Después del step: Pesos actualizados [[ 0.7838112  -0.12013291]]\n",
            "tensor([4., 5.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 4:\n",
            "  Antes del backward: Pesos [[ 0.7838112  -0.12013291]]\n",
            "  Gradientes calculadas: [[-0.51301    -0.64126253]]\n",
            "  Después del step: Pesos actualizados [[ 0.8351122  -0.05600666]]\n",
            "\n",
            "--- Epoch 4 ---\n",
            "tensor([1., 2.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 1:\n",
            "  Antes del backward: Pesos [[ 0.8351122  -0.05600666]]\n",
            "  Gradientes calculadas: [[0.5294267 1.0588534]]\n",
            "  Después del step: Pesos actualizados [[ 0.7821695 -0.161892 ]]\n",
            "tensor([2., 3.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 2:\n",
            "  Antes del backward: Pesos [[ 0.7821695 -0.161892 ]]\n",
            "  Gradientes calculadas: [[1.2071886 1.8107829]]\n",
            "  Después del step: Pesos actualizados [[ 0.6614507 -0.3429703]]\n",
            "tensor([3., 4.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 3:\n",
            "  Antes del backward: Pesos [[ 0.6614507 -0.3429703]]\n",
            "  Gradientes calculadas: [[-1.579491 -2.105988]]\n",
            "  Después del step: Pesos actualizados [[ 0.8193998 -0.1323715]]\n",
            "tensor([4., 5.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 4:\n",
            "  Antes del backward: Pesos [[ 0.8193998 -0.1323715]]\n",
            "  Gradientes calculadas: [[-0.498286  -0.6228575]]\n",
            "  Después del step: Pesos actualizados [[ 0.86922836 -0.07008575]]\n",
            "\n",
            "--- Epoch 5 ---\n",
            "tensor([1., 2.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 1:\n",
            "  Antes del backward: Pesos [[ 0.86922836 -0.07008575]]\n",
            "  Gradientes calculadas: [[0.51889235 1.0377847 ]]\n",
            "  Después del step: Pesos actualizados [[ 0.8173391  -0.17386422]]\n",
            "tensor([2., 3.], grad_fn=<UnbindBackward0>) tensor([0.])\n",
            "Batch 2:\n",
            "  Antes del backward: Pesos [[ 0.8173391  -0.17386422]]\n",
            "  Gradientes calculadas: [[1.2010942 1.8016412]]\n",
            "  Después del step: Pesos actualizados [[ 0.6972297  -0.35402834]]\n",
            "tensor([3., 4.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 3:\n",
            "  Antes del backward: Pesos [[ 0.6972297  -0.35402834]]\n",
            "  Gradientes calculadas: [[-1.5673195 -2.0897593]]\n",
            "  Después del step: Pesos actualizados [[ 0.85396165 -0.1450524 ]]\n",
            "tensor([4., 5.], grad_fn=<UnbindBackward0>) tensor([1.])\n",
            "Batch 4:\n",
            "  Antes del backward: Pesos [[ 0.85396165 -0.1450524 ]]\n",
            "  Gradientes calculadas: [[-0.4863708 -0.6079635]]\n",
            "  Después del step: Pesos actualizados [[ 0.90259874 -0.08425605]]\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento del modelo\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print(f'\\n--- Epoch {epoch + 1} ---')\n",
        "\n",
        "    for i, (data, target) in enumerate(zip(X, y)):\n",
        "        print(data, target)\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        # Calculamos la perdida con la función\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        print(f'Batch {i + 1}:')\n",
        "        print(f'  Antes del backward: Pesos {model[0].weight.data.numpy()}')\n",
        "\n",
        "        # Realizamos la Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        print(f'  Gradientes calculadas: {model[0].weight.grad.numpy()}')\n",
        "\n",
        "        # Actualizamos los pesos\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'  Después del step: Pesos actualizados {model[0].weight.data.numpy()}')\n",
        "\n",
        "        # Ponemos a cero los gradientes\n",
        "        optimizer.zero_grad()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An9tMmgPpuDy",
        "outputId": "a4fe71a6-fe41-4614-f14a-e5fd676a9efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicciones después del entrenamiento:\n",
            "tensor([[0.5083],\n",
            "        [0.7009],\n",
            "        [0.8415],\n",
            "        [0.9233]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predicción final después de entrenamiento\n",
        "with torch.no_grad():\n",
        "    predicted = model(X)\n",
        "    print(\"\\nPredicciones después del entrenamiento:\")\n",
        "    print(predicted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB58X8eGrg0j"
      },
      "source": [
        "Verificamos la actualización de pesos:\n",
        "\n",
        "\n",
        "![1_2wULsk4M4HG12bZ5cB-bPA.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEe4xyeBrhCG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
